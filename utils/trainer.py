import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from tqdm import tqdm
import os
import logging
from torch.utils.data import Dataset
from typing import Optional
from copy import deepcopy

# é…ç½®ä¸€ä¸ªç®€å•çš„æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

class Trainer:
    """
    ä¸€ä¸ªé€šç”¨çš„è®­ç»ƒå™¨ç±»ï¼Œå°è£…äº†æ ‡å‡†çš„è®­ç»ƒå’ŒéªŒè¯æµç¨‹ã€‚
    """
    def __init__(self, 
                 model: nn.Module,
                 optimizer: torch.optim.Optimizer,
                 loss_fn: nn.Module,
                 train_loader: DataLoader,
                 val_loader: DataLoader,
                 synthetic_dataset: Dataset,
                 lr_scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
                 device: str = 'cuda',
                 epochs: int = 100,
                 val_train_epochs: int = 5,
                 checkpoint_dir: str = 'output/checkpoints'):
        """
        åˆå§‹åŒ– Trainerã€‚

        Args:
            model (nn.Module): éœ€è¦è®­ç»ƒçš„æ¨¡å‹ã€‚
            optimizer (Optimizer): ä¼˜åŒ–å™¨ã€‚
            loss_fn (nn.Module): æŸå¤±å‡½æ•°ã€‚
            train_loader (DataLoader): è®­ç»ƒæ•°æ®åŠ è½½å™¨ã€‚
            val_loader (DataLoader): éªŒè¯æ•°æ®åŠ è½½å™¨ã€‚
            lr_scheduler (Scheduler, optional): å­¦ä¹ ç‡è°ƒåº¦å™¨ã€‚
            device (str): è®­ç»ƒè®¾å¤‡ ('cuda' or 'cpu')ã€‚
            epochs (int): è®­ç»ƒçš„æ€»è½®æ•°ã€‚
            checkpoint_dir (str): ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹çš„ç›®å½•ã€‚
        """
        self.model = model.to(device)
        self.optimizer = optimizer
        self.loss_fn = loss_fn
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.synthetic_dataset = synthetic_dataset
        self.lr_scheduler = lr_scheduler
        self.device = device
        self.epochs = epochs
        self.checkpoint_dir = checkpoint_dir
        self.val_train_epochs = val_train_epochs
        
        self.best_val_acc = 0.0
        os.makedirs(self.checkpoint_dir, exist_ok=True)

    def train(self):
        """
        å¯åŠ¨å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€‚
        """
        logging.info("Starting training...")
        for epoch in range(1, self.epochs + 1):
            # è®­ç»ƒä¸€ä¸ª epoch
            train_loss = self._train_one_epoch(epoch)
            
            # éªŒè¯ä¸€ä¸ª epoch
            val_acc = self._evaluate_synthetic_data_quality(epoch)
            
            # æ›´æ–°å­¦ä¹ ç‡
            if self.lr_scheduler:
                self.lr_scheduler.step()
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹å¹¶ä¿å­˜
            is_best = val_acc > self.best_val_acc
            if is_best:
                self.best_val_acc = val_acc
                logging.info(f"ğŸ‰ New best synthetic data found! Validation accuracy: {val_acc:.2f}%")
            
            self._save_checkpoint(epoch, is_best)
        
        logging.info("Training complete.")

    def _train_one_epoch(self, epoch: int) -> float:
        """
        æ‰§è¡Œå•è½®è®­ç»ƒã€‚
        ã€æœ€ç»ˆæ­£ç¡®ç‰ˆæœ¬ã€‘
        æœ¬æ–¹æ³•æ¥æ”¶ä¸€ä¸ªè¢«æ‰“ä¹±çš„æ•°æ®åŠ è½½å™¨ï¼Œå¹¶åœ¨å†…éƒ¨é‡å»ºâ€œæŒ‰ç±»åˆ«â€åŒ¹é…çš„é€»è¾‘ã€‚
        """
        self.model.train() # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
        total_loss = 0.0
        
        # ä½¿ç”¨ self.train_loader (å®ƒå°†è¢«è®¾ç½®æˆ syn_loader)
        progress_bar = tqdm(self.train_loader, desc=f"Epoch {epoch}/{self.epochs} [Training on Synthetic Data]")
        for batch in progress_bar:
            
            # --- ã€æ ¸å¿ƒä¿®æ”¹å¼€å§‹ã€‘ ---

            # 1. è·å–æ•´ä¸ªæ‰¹æ¬¡çš„æ•°æ®å’Œæ ‡ç­¾
            syn_aud_batch = batch['audio'].to(self.device)
            syn_img_batch = batch['frame'].to(self.device)
            labels_batch = batch['label'].to(self.device)

            # 2. æˆ‘ä»¬å°†åœ¨æ¯ä¸ªç±»åˆ«ä¸Šç´¯ç§¯æ¢¯åº¦ï¼Œæœ€åä¸€èµ·æ›´æ–°
            self.optimizer.zero_grad()
            
            # 3. æŒ‰ç±»åˆ«å¯¹æ‰¹æ¬¡æ•°æ®è¿›è¡Œâ€œè§£å¤ç”¨â€ (Demultiplexing)
            #    æ‰¾å‡ºå½“å‰æ‰¹æ¬¡ä¸­å‡ºç°äº†å“ªäº›ç±»åˆ«
            unique_classes_in_batch = torch.unique(labels_batch)
            
            batch_total_loss = 0.0

            # 4. ä¸ºæ¯ä¸ªç±»åˆ«ç‹¬ç«‹è®¡ç®—æŸå¤±å¹¶ç´¯ç§¯æ¢¯åº¦
            for c in unique_classes_in_batch:
                # 4.1. ç­›é€‰å‡ºå½“å‰æ‰¹æ¬¡ä¸­æ‰€æœ‰å±äºç±»åˆ« c çš„åˆæˆæ•°æ®
                class_mask = (labels_batch == c)
                curr_aud_syn = syn_aud_batch[class_mask]
                curr_img_syn = syn_img_batch[class_mask]

                # 4.2. å‰å‘ä¼ æ’­ (åªå¯¹å½“å‰ç±»åˆ«çš„æ•°æ®)
                inputs = {"audio": curr_aud_syn, "image": curr_img_syn}
                features = self.model.forward(inputs, mode="embeddings")
                embed_audio = features["audio"]
                embed_image = features["vision"]
                
                # 4.3. è®¡ç®—ç±»åˆ« c çš„å†…éƒ¨å¯¹æ¯”æŸå¤±
                loss_c = self.loss_fn(embed_audio, embed_audio, embed_image, embed_image)
                
                # 4.4. åå‘ä¼ æ’­ä»¥ã€ç´¯ç§¯ã€‘æ¢¯åº¦
                #      ä¸ºäº†é˜²æ­¢æ ·æœ¬æ•°å¤šçš„ç±»åˆ«ä¸»å¯¼æ¢¯åº¦ï¼Œæˆ‘ä»¬å°†æŸå¤±æŒ‰ç±»åˆ«æ•°è¿›è¡Œå¹³å‡
                loss_c_avg = loss_c / len(unique_classes_in_batch)
                loss_c_avg.backward()

                batch_total_loss += loss_c.item() # è®°å½•åŸå§‹æŸå¤±å¤§å°
            
            # 5. åœ¨å¤„ç†å®Œæ‰¹æ¬¡ä¸­æ‰€æœ‰ç±»åˆ«çš„æ¢¯åº¦ç´¯ç§¯åï¼Œæ‰§è¡Œä¸€æ¬¡ä¼˜åŒ–å™¨æ­¥éª¤
            #    è¿™å°†ä½¿ç”¨ç´¯ç§¯çš„æ¢¯åº¦ï¼ŒåŒæ—¶æ›´æ–°æ‰¹æ¬¡ä¸­æ‰€æœ‰è¢«è®¡ç®—è¿‡çš„åˆæˆæ•°æ®
            self.optimizer.step()
            
            # 6. æ›´æ–°æ€»æŸå¤±å’Œè¿›åº¦æ¡
            total_loss += batch_total_loss
            progress_bar.set_postfix(batch_loss=batch_total_loss / len(unique_classes_in_batch))
            
            # --- ã€æ ¸å¿ƒä¿®æ”¹ç»“æŸã€‘ ---
            
        avg_loss = total_loss / len(self.train_loader)
        logging.info(f"Epoch {epoch} Training Summary: Average Loss: {avg_loss:.4f}")
        return avg_loss
    
    def _save_checkpoint(self, epoch: int, is_best: bool):
        """
        ä¿å­˜æ£€æŸ¥ç‚¹ã€‚
        ã€å·²ä¸ºä½ å®šåˆ¶ï¼Œä»¥é€‚åº”æ•°æ®è’¸é¦ä»»åŠ¡ã€‘
        è¿™ä¸ªæ–¹æ³•ç°åœ¨ä¿å­˜çš„æ˜¯åˆæˆæ•°æ®å’Œå®ƒçš„ä¼˜åŒ–å™¨çŠ¶æ€ã€‚
        """
        # 1. å‡†å¤‡è¦ä¿å­˜çš„çŠ¶æ€å­—å…¸
        state = {
            'epoch': epoch,
            'best_val_acc': self.best_val_acc,
            'optimizer_state_dict': self.optimizer.state_dict(),
            'synthetic_audio_data': self.synthetic_dataset.audio,
            'synthetic_image_data': self.synthetic_dataset.images,
            'synthetic_labels': self.synthetic_dataset.labels # å¦‚æœæ ‡ç­¾ä¹Ÿæ˜¯å¯å­¦ä¹ çš„
        }
        
        if self.lr_scheduler:
            state['scheduler_state_dict'] = self.lr_scheduler.state_dict()
            
        # 2. å®šä¹‰æ–‡ä»¶å
        filename = os.path.join(self.checkpoint_dir, f"checkpoint_epoch_{epoch}.pth")
        
        # 3. ä¿å­˜æ£€æŸ¥ç‚¹
        torch.save(state, filename)
        logging.info(f"Saved synthetic data checkpoint: {filename}")
        
        # 4. å¦‚æœæ˜¯å½“å‰æœ€å¥½çš„ç»“æœï¼Œé¢å¤–ä¿å­˜ä¸€ä»½ä¸º 'best_syn_data.pth'
        if is_best:
            best_filename = os.path.join(self.checkpoint_dir, "best_syn_data.pth")
            torch.save(state, best_filename)
            logging.info(f"ğŸ‰ Saved best synthetic data to: {best_filename}")

    def _evaluate_synthetic_data_quality(self, epoch: int) -> float:
        """
        é€šè¿‡åªè®­ç»ƒæ¨¡å‹åˆ†ç±»å¤´å¹¶åœ¨çœŸå®æµ‹è¯•é›†ä¸Šè¯„ä¼°ï¼Œæ¥è¡¡é‡åˆæˆæ•°æ®çš„è´¨é‡ã€‚
        ã€å·²ä¸ºä½ æ¨¡å‹çš„ ImageBindClassifier ç»“æ„ç²¾ç¡®å®šåˆ¶ã€‘
        """
        logging.info(f"--- Starting validation for epoch {epoch}: Evaluating synthetic data quality ---")

        # --- æ­¥éª¤ 1: å‡†å¤‡ä¸€ä¸ªç”¨äºè¯„ä¼°çš„â€œå­¦ç”Ÿâ€æ¨¡å‹å‰¯æœ¬ ---
        # æˆ‘ä»¬ä½¿ç”¨åŸå§‹æ•™å¸ˆæ¨¡å‹çš„ä¸€ä¸ªæ·±æ‹·è´ï¼Œä»¥ç¡®ä¿åŸå§‹æ¨¡å‹ä¸å—å½±å“
        student_model = deepcopy(self.model)
        student_model.to(self.device)

        # --- æ­¥éª¤ 2: å†»ç»“ç‰¹å¾æå–å™¨ï¼Œåªè®­ç»ƒåˆ†ç±»å¤´ ---
        # å†»ç»“æ‰€æœ‰å‚æ•°
        for param in student_model.parameters():
            param.requires_grad = False
        
        # ç„¶åï¼Œåªè§£å†»ä½ æŒ‡å®šçš„åˆ†ç±»å¤´çš„å‚æ•°
        logging.info("Unfreezing classifier weights for validation training...")
        for param in student_model.classifier_audio.parameters():
            param.requires_grad = True
        for param in student_model.classifier_image.parameters():
            param.requires_grad = True
        
        # åˆ›å»ºä¸€ä¸ªåªåŒ…å«å¯è®­ç»ƒå‚æ•°çš„ä¼˜åŒ–å™¨
        trainable_params = filter(lambda p: p.requires_grad, student_model.parameters())
        optimizer_student = torch.optim.Adam(trainable_params, lr=0.001)
        
        loss_fn_student = nn.CrossEntropyLoss()
        # è®­ç»ƒæ•°æ®åŠ è½½å™¨å°±æ˜¯ self.train_loader (syn_loader)
        inner_train_loader = self.train_loader 

        # --- æ­¥éª¤ 3: å†…éƒ¨å¿«é€Ÿè®­ç»ƒå¾ªç¯ ---
        logging.info(f"Training classifier head for {self.val_train_epochs} epochs on synthetic data...")
        student_model.train() # å°†å­¦ç”Ÿæ¨¡å‹è®¾ä¸ºè®­ç»ƒæ¨¡å¼
        for inner_epoch in range(self.val_train_epochs):
            for batch in inner_train_loader:
                inputs = { "audio": batch['audio'].to(self.device), "image": batch['frame'].to(self.device) }
                labels = batch['label'].to(self.device)

                optimizer_student.zero_grad()
                
                # ç›´æ¥è°ƒç”¨æ¨¡å‹çš„ forward æ–¹æ³•ï¼Œå®ƒä¼šè¿”å›æœ€ç»ˆçš„é¢„æµ‹æ¦‚ç‡
                predictions = student_model.forward(inputs)
                
                loss = loss_fn_student(predictions, labels)
                
                loss.backward()
                optimizer_student.step()
        
        # --- æ­¥éª¤ 4: åœ¨çœŸå®æµ‹è¯•é›†ä¸Šè¯„ä¼°è®­ç»ƒå¥½çš„å­¦ç”Ÿæ¨¡å‹ ---
        logging.info("Evaluating the trained student model on the real test set...")
        student_model.eval() # å°†å­¦ç”Ÿæ¨¡å‹è®¾ä¸ºè¯„ä¼°æ¨¡å¼
        correct = 0
        total = 0
        with torch.no_grad():
            for batch in self.val_loader: # self.val_loader æ˜¯çœŸå®çš„ test_loader
                inputs = { "audio": batch['audio'].to(self.device), "image": batch['frame'].to(self.device) }
                labels = batch['label'].to(self.device)
                
                # è·å¾—æœ€ç»ˆçš„é¢„æµ‹æ¦‚ç‡
                outputs = student_model.forward(inputs)
                # ä»æ¦‚ç‡ä¸­å¾—åˆ°é¢„æµ‹çš„ç±»åˆ«
                _, predicted = torch.max(outputs.data, 1)
                
                total += labels.size(0)
                correct += (predicted == labels).sum().item()
        
        accuracy = 100 * correct / total
        logging.info(f"Validation Summary: Student model accuracy on real test data: {accuracy:.2f}%")
        
        del student_model # é‡Šæ”¾å‰¯æœ¬å ç”¨çš„æ˜¾å­˜
        return accuracy